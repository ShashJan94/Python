{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f92fe6-a39b-4a38-a29b-03b384e230cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from imutils.contours import sort_contours\n",
    "import argparse\n",
    "import imutils\n",
    "from operator import itemgetter\n",
    "coords,lines = [],[]\n",
    "i=0\n",
    "def capture_handwriting_coordinates():\n",
    "    cap = cv2.VideoCapture(0) # open the webcam\n",
    "     # set video height\n",
    "    while True:\n",
    "        ret, frame = cap.read() # read the webcam frame\n",
    "        cv2.imshow(\"Webcam\", frame) # display the frame\n",
    "        \n",
    "        # get the mouse events\n",
    "        events = cv2.setMouseCallback(\"Webcam\", get_coordinates,frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "    cap.release() # release the webcam\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def get_coordinates(event, x, y, flags, param):\n",
    "    global coords,i,lines\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        coords.clear()\n",
    "        lines.clear()\n",
    "    elif event==cv2.EVENT_MOUSEMOVE:\n",
    "        if flags == cv2.EVENT_FLAG_LBUTTON:\n",
    "            if not coords:\n",
    "                coords.append((round(x), round(y)))\n",
    "            else:\n",
    "                coords.append((round(x), round(y)))\n",
    "                lines.append(cv2.polylines(param, [np.array(coords)], False, (0,255,0), thickness=5))\n",
    "                cv2.imshow(\"Webcam\",param)\n",
    "                cv2.waitKey(1000)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "            img = np.zeros((500,500,3), np.uint8)\n",
    "            lines.append(cv2.polylines(img, [np.array(coords)], False, (255,255,255), thickness=5))\n",
    "            if cv2.imwrite(\"C:/Users/ctgfa/CamImage/handwritten(\"+str(i)+\")\"+\".png\", img):\n",
    "                print(\"Image Saved!\")\n",
    "def get_image():\n",
    "    folder_path = 'C:/Users/ctgfa/CamImage/'\n",
    "    files = os.listdir(folder_path)\n",
    "    if len(files)>0:\n",
    "        # Get the creation time of each file\n",
    "            files_ctime = [(f, os.path.getctime(os.path.join(folder_path, f))) for f in files]\n",
    "\n",
    "            # Sort the files by their creation time\n",
    "            files_ctime.sort(key=itemgetter(1))\n",
    "\n",
    "            # Get the last file\n",
    "            last_file = files_ctime[-1][0]\n",
    "            try:\n",
    "                for file in files:\n",
    "                    if file != last_file:\n",
    "                        os.remove(os.path.join(folder_path, file))\n",
    "            except Exception as e:\n",
    "                        print(f'Error occured while deleting {file_path} : {e}')\n",
    "    else: \n",
    "            print(\"There are no files\")\n",
    "\n",
    "capture_handwriting_coordinates()\n",
    "get_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41da9e0a-7ed5-413c-b8f6-f0762a4de0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Saved\n"
     ]
    }
   ],
   "source": [
    "from imutils.contours import sort_contours\n",
    "import argparse\n",
    "import imutils\n",
    "\n",
    "# Load the webcam picture\n",
    "img = cv2.imread(\"C:/Users/ctgfa/CamImage/handwritten(0).png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(thresh, 100, 150)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Extract the ROI containing the handwriting\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    if w*h > 100:\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        resized_image = cv2.resize(roi, dsize=(28, 28))\n",
    "        gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "if cv2.imwrite('C:/Users/ctgfa/CamImage/handwritten_image1.jpg', gray_image):\n",
    "    print(\"Image Saved\")\n",
    "gray_image = gray_image/255\n",
    "window_name = 'image'\n",
    "  \n",
    "# Using cv2.imshow() method\n",
    "# Displaying the image\n",
    "cv2.imshow(window_name, gray_image)\n",
    "# Save the extracted image\n",
    "cv2.waitKey(0)\n",
    "  \n",
    "# closing all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb32e15-e8f9-43d9-a741-c4ada15d180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "975/975 [==============================] - 37s 23ms/step - loss: 1.0092 - accuracy: 0.6958 - val_loss: 0.4094 - val_accuracy: 0.8725\n",
      "Epoch 2/10\n",
      "975/975 [==============================] - 22s 22ms/step - loss: 0.5659 - accuracy: 0.8236 - val_loss: 0.3358 - val_accuracy: 0.8974\n",
      "Epoch 3/10\n",
      "975/975 [==============================] - 22s 23ms/step - loss: 0.4776 - accuracy: 0.8487 - val_loss: 0.3017 - val_accuracy: 0.9054\n",
      "Epoch 4/10\n",
      "975/975 [==============================] - 22s 22ms/step - loss: 0.4379 - accuracy: 0.8613 - val_loss: 0.2889 - val_accuracy: 0.9087\n",
      "Epoch 5/10\n",
      "975/975 [==============================] - 21s 22ms/step - loss: 0.4061 - accuracy: 0.8696 - val_loss: 0.2721 - val_accuracy: 0.9147\n",
      "Epoch 6/10\n",
      "975/975 [==============================] - 21s 21ms/step - loss: 0.3842 - accuracy: 0.8773 - val_loss: 0.2648 - val_accuracy: 0.9168\n",
      "Epoch 7/10\n",
      "975/975 [==============================] - 21s 21ms/step - loss: 0.3629 - accuracy: 0.8833 - val_loss: 0.2618 - val_accuracy: 0.9170\n",
      "Epoch 8/10\n",
      "975/975 [==============================] - 21s 21ms/step - loss: 0.3440 - accuracy: 0.8871 - val_loss: 0.2521 - val_accuracy: 0.9207\n",
      "Epoch 9/10\n",
      "975/975 [==============================] - 21s 21ms/step - loss: 0.3297 - accuracy: 0.8927 - val_loss: 0.2514 - val_accuracy: 0.9212\n",
      "Epoch 10/10\n",
      "975/975 [==============================] - 20s 21ms/step - loss: 0.3154 - accuracy: 0.8961 - val_loss: 0.2486 - val_accuracy: 0.9200\n",
      "Test loss: 0.24858790636062622\n",
      "Test accuracy: 0.9200480580329895\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from mnist.loader import MNIST\n",
    "\n",
    "emnist_data = MNIST(path='gzip\\\\', return_type='numpy')\n",
    "emnist_data.select_emnist('letters')\n",
    "x_train, y_train = emnist_data.load_training()\n",
    "x_test,y_test = emnist_data.load_testing()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y_train = to_categorical(y_train, dtype = \"uint8\")\n",
    "y_test = to_categorical(y_test, dtype = \"uint8\")\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(27, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "# evaluate the model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save('alphabet_recognition_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e340497-18b0-4daf-8c8e-5a95fdcef095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f65743a-dfee-43f9-8b92-65ccf1cfe329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "[[[  0.   0.   0.]\n",
      "  [  1.   1.   1.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  1.   1.   1.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  3.   3.   3.]\n",
      "  ...\n",
      "  [  1.   1.   1.]\n",
      "  [  1.   1.   1.]\n",
      "  [255. 255. 255.]]\n",
      "\n",
      " [[  2.   2.   2.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [255. 255. 255.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  2.   2.   2.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[  3.   3.   3.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.]\n",
      "  [  2.   2.   2.]\n",
      "  [  1.   1.   1.]\n",
      "  ...\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]\n",
      "  [  0.   0.   0.]]]\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "G\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "ALPHABET = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\n",
    "ALPHABET = ALPHABET\n",
    "print(ALPHABET)\n",
    "model = keras.models.load_model('handwriting_recognition.h5')\n",
    "img = cv2.imread(\"C:/Users/ctgfa/CamImage/handwritten_image1.jpg\")\n",
    "img_arr = tf.keras.preprocessing.image.img_to_array(img)\n",
    "print(img_arr)\n",
    "img_arr= img_arr.reshape(-1, 28, 28, 1)\n",
    "predictions = model.predict(img_arr)\n",
    "alphabet_index = tf.argmax(predictions[0])\n",
    "alphabet = ALPHABET[alphabet_index]\n",
    "print(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd6aae-9cbf-4169-9d57-9965c9a93d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
